{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model using Scikit-learn and Keras wrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "['CYTDK2' 'XPPT' 'HXPRT' ... 'FORCT_rev' 'EX_3hpp_e_i' 'HADPCOADH3_rev']\n",
      "number of metabolites:  1877\n",
      "filtered measurements size:  1\n",
      "dataset file: ../data/Dataset/iML1515_EXP_paul_UB.npz\n",
      "model type: AMNWt\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (186, 49) (186, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from amn.model import AMNWtModel\n",
    "from amn.model import AMRNNModel\n",
    "\n",
    "model_class = AMRNNModel\n",
    "# model_class = AMNWtModel\n",
    "\n",
    "data_dir = \"../data\"\n",
    "seed = 10\n",
    "# np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# dataset_file = \"/Dataset/IJN1463_EXP_UB_Anne.npz\"\n",
    "# objective=['BIOMASS_KT2440_WT3']\n",
    "\n",
    "# dataset_file = \"/Dataset/IJN1463_10_UB.npz\"\n",
    "# objective=['BIOMASS_KT2440_WT3']\n",
    "\n",
    "# dataset_file = \"/Dataset/e_coli_core_UB_100.npz\"\n",
    "# objective=['BIOMASS_Ecoli_core_w_GAM']\n",
    "# epochs = 200\n",
    "# batch_size = 7\n",
    "# uptake_max_index = None\n",
    "\n",
    "dataset_file = \"/Dataset/e_coli_core_UB.npz\"\n",
    "objective=['BIOMASS_Ecoli_core_w_GAM']\n",
    "uptake_max_index = None\n",
    "epochs = 20 #200\n",
    "batch_size = 7\n",
    "\n",
    "\n",
    "# dataset_file = \"/Dataset/biolog_iML1515_EXP_UB.npz\"\n",
    "# objective=['BIOMASS_Ec_iML1515_core_75p37M']\n",
    "# epochs = 1 #20\n",
    "# batch_size = 30\n",
    "# uptake_max_index=151\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = model_class(dataset_file=data_dir + dataset_file, \n",
    "                   objective=objective,\n",
    "                   timestep=4,\n",
    "                   hidden_dim=50,\n",
    "                   verbose=True,\n",
    "                   uptake_max_index = uptake_max_index)\n",
    "model.printout()\n",
    "\n",
    "# Preprocessing\n",
    "from amn.tools import MaxScaler\n",
    "scaler= MaxScaler()\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.preprocess(scaler)\n",
    "model.preprocessing_for_specific_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 14:40:35.991803: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 14:40:35.993384: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-09 14:40:36.007946: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 14:40:36.010370: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-09 14:40:36.011686: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 14:40:36.012928: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-09 14:40:36.014898: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 14:40:36.016069: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-09 14:40:36.018709: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 14:40:36.020510: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-09 14:40:36.144135: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-09 14:40:36.163508: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-09 14:40:36.164023: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-09 14:40:36.164311: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-09 14:40:36.169019: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([14.91294599, 22.20490575, 13.78981233, 15.43258643, 15.91683006]),\n",
       " 'score_time': array([0.94125652, 0.27923036, 1.28827071, 0.64941287, 0.49342775]),\n",
       " 'test_loss_constraint': array([0.00376069, 0.00415281, 0.00352208, 0.00386676, 0.00399523]),\n",
       " 'train_loss_constraint': array([0.00383015, 0.00399166, 0.00358072, 0.00375434, 0.00407531]),\n",
       " 'test_mse': array([0.00366208, 0.00394042, 0.00519764, 0.00351517, 0.00373788]),\n",
       " 'train_mse': array([0.00372008, 0.00384605, 0.00536005, 0.00332458, 0.00387086]),\n",
       " 'test_R2': array([0.7911341 , 0.81550174, 0.38100968, 0.86698227, 0.81566853]),\n",
       " 'train_R2': array([0.80389084, 0.79766492, 0.37770605, 0.87800637, 0.811624  ])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# cross validation\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "estimator= KerasRegressor(build_fn=model.build_model, \n",
    "                          epochs=epochs, \n",
    "                          batch_size=batch_size, \n",
    "                          verbose=0)\n",
    "\n",
    "scoring = {\"loss_constraint\":make_scorer(model.loss_constraint),\n",
    "           \"mse\":make_scorer(model.mse),\n",
    "           \"R2\":make_scorer(model.R2),\n",
    "           }\n",
    "\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_params = {'callbacks': [callback]}\n",
    "fit_params = {}\n",
    "\n",
    "kfold= KFold(n_splits=5,shuffle=True, random_state=seed)\n",
    "\n",
    "results=cross_validate(estimator, \n",
    "                       model.X_train, \n",
    "                       model.Y_train, \n",
    "                       cv=kfold, \n",
    "                       n_jobs=5, \n",
    "                       scoring=scoring, \n",
    "                       fit_params=fit_params,\n",
    "                       return_train_score=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_loss_constraint</th>\n",
       "      <th>train_loss_constraint</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>test_R2</th>\n",
       "      <th>train_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.451416</td>\n",
       "      <td>0.730320</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.734059</td>\n",
       "      <td>0.733778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.312003</td>\n",
       "      <td>0.394319</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.199288</td>\n",
       "      <td>0.201647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.789812</td>\n",
       "      <td>0.279230</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.381010</td>\n",
       "      <td>0.377706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.912946</td>\n",
       "      <td>0.493428</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.791134</td>\n",
       "      <td>0.797665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.432586</td>\n",
       "      <td>0.649413</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.815502</td>\n",
       "      <td>0.803891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.916830</td>\n",
       "      <td>0.941257</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.815669</td>\n",
       "      <td>0.811624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.204906</td>\n",
       "      <td>1.288271</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.866982</td>\n",
       "      <td>0.878006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit_time  score_time  test_loss_constraint  train_loss_constraint  \\\n",
       "count   5.000000    5.000000              5.000000               5.000000   \n",
       "mean   16.451416    0.730320              0.003860               0.003846   \n",
       "std     3.312003    0.394319              0.000239               0.000195   \n",
       "min    13.789812    0.279230              0.003522               0.003581   \n",
       "25%    14.912946    0.493428              0.003761               0.003754   \n",
       "50%    15.432586    0.649413              0.003867               0.003830   \n",
       "75%    15.916830    0.941257              0.003995               0.003992   \n",
       "max    22.204906    1.288271              0.004153               0.004075   \n",
       "\n",
       "       test_mse  train_mse   test_R2  train_R2  \n",
       "count  5.000000   5.000000  5.000000  5.000000  \n",
       "mean   0.004011   0.004024  0.734059  0.733778  \n",
       "std    0.000681   0.000778  0.199288  0.201647  \n",
       "min    0.003515   0.003325  0.381010  0.377706  \n",
       "25%    0.003662   0.003720  0.791134  0.797665  \n",
       "50%    0.003738   0.003846  0.815502  0.803891  \n",
       "75%    0.003940   0.003871  0.815669  0.811624  \n",
       "max    0.005198   0.005360  0.866982  0.878006  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 14:41:08.009841: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 14:41:08.013006: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-09 14:41:08.209271: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 0.8440483586310867\n",
      "Q2 : 0.8478538192871721\n"
     ]
    }
   ],
   "source": [
    "AMNWt_model = model.build_model()\n",
    "history = AMNWt_model.fit(model.X_train, model.Y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print(\"R2 :\", model.R2(model.Y_train, AMNWt_model.predict(model.X_train)))\n",
    "print(\"Q2 :\", model.R2(model.Y_test, AMNWt_model.predict(model.X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agiralt/anaconda3/envs/amn/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3638d3a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3638e48e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimator= KerasRegressor(build_fn=model.build_model, \n",
    "                          epochs=epochs, \n",
    "                          batch_size=batch_size, \n",
    "                          verbose=0)\n",
    "\n",
    "distributions = dict(batch_size=[7,20],\n",
    "                     nb_epoch=[2,100],\n",
    "                    #  hidden_dim=[1,2],\n",
    "                     )\n",
    "\n",
    "scoring = {\"loss_constraint\":make_scorer(model.loss_constraint),\n",
    "           \"mse\":make_scorer(model.mse),\n",
    "           \"R2\":make_scorer(model.R2),\n",
    "           }\n",
    "\n",
    "clf = RandomizedSearchCV(estimator, distributions, random_state=0)\n",
    "search = clf.fit(model.X_test, model.Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f36a01583d0>,\n",
       "                   param_distributions={'batch_size': [7, 20],\n",
       "                                        'nb_epoch': [2, 100]},\n",
       "                   random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
